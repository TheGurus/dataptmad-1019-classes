{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do computers process text?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have learned how to train algorithms to manage data that comes in the form of numbers, or categories, which we can then translate into numbers. But how do we do this with text? There are several ways of vectorizing text data, or translating it from words into numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning - Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are common words that do not necessarily add meaning (a, to, like...). For this reason, we remove these types of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stemming is the process of removing common prefixes or suffixes\n",
    "- Lemmatization is the process by which words are replaced by their roots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- organizing:\n",
    "    - stemming: organiz\n",
    "    - lemmatization: organize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique turns text content into a matrix of integers which corresponds words with the number of times those words appear in the corpus, with each row representing a document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**email spam detection example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency - Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as in Bag of Words, in TF-IDF, each term in the corpus receives a scoring that is entered into a matrix. This score is derived through the calculation of two numbers, the term frequency, and the inverse document frequency, which are then multiplied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Term Frequency is the number of times the term appears in the document divided by the total number of words of the document\n",
    "- Inverse Document Frequency is a measure of how frequency a document containing the word appears in the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Frequency:\n",
    "- my car is beautiful -> scoring for car: 1 / 4\n",
    "\n",
    "Inverse Document Frequency:\n",
    "- my car is beautiful\n",
    "- my love is pure\n",
    "- I saw and angel -> scoring for car: log(3 / 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_\"the lower the score, the more common the word (mostly because the inverse document frequency will be very small due to the logarithm with a large base will result in a very small decimal). The higher the score, the rarer the word.\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__In TF-IDF the scoring depends on your content and the rest of documents content. In BoW the scoring only depends on the current document__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is the state-of-the-art in NLP. It consists on getting a vector representation of a word or a document from a pretrained model (usually a neural network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my car is very beautiful\n",
    "\n",
    "my car is ___ beautiful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my car is very beautiful -> (0.3,0.4,0.1.......0.4,0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ironhack_env]",
   "language": "python",
   "name": "conda-env-ironhack_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
